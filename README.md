# ğŸ“„ **README.md**

# Bag-of-Visual-Words Scene Classification  
### SIFT + Swin-B Hybrid Descriptor System  
CMPE 537 â€“ Computer Vision (Fall 2025)

This repository implements a **Bag-of-Visual-Words (BoVW)** classification pipeline on the **MIT Indoor Scenes** dataset using both **traditional SIFT descriptors** and **modern Swin-B Transformer features**.  
The project includes feature extraction, quantization via k-means, histogram construction, and classification using SVMs with linear and Chi-Squared kernels.

---

## ğŸ“ Project Structure

``` ngsx
project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Images/                 # MIT Indoor Scenes dataset
â”‚   â”œâ”€â”€ descriptors/            # Extracted SIFT/Swin-B descriptors
â”‚   â””â”€â”€ histograms/             # K-means BoVW histograms
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ feature_extraction/     # SIFT & Swin-B feature modules
â”‚   â”œâ”€â”€ models/                 # SVM, classifiers, helpers
â”‚   â”œâ”€â”€ utils/                  # Preprocessing, scaling
â”‚   â””â”€â”€ train.py                # End-to-end training script
â”œâ”€â”€ results/                    # Evaluation outputs, confusion matrices
â”œâ”€â”€ checkpoints/                # Saved models & cluster centers
â”œâ”€â”€ predict.py                  # Single-image prediction script
â””â”€â”€ README.md
``` 

---

## ğŸ“¦ Installation

### 1. Clone the repository  
```bash
git clone https://github.com/username/bovw-sift-swinb.git
cd bovw-sift-swinb
````

### 2. Create virtual environment

```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ“Š Dataset

The project uses the **MIT Indoor Scenes** dataset:

* **67 scene classes**
* Train/test file lists: `TrainImages.txt`, `TestImages.txt`
* Each descriptor type stored separately

  * `data/descriptors/sift/`
  * `data/descriptors/swin/`

---

## ğŸ§© Feature Extraction

### âœ”ï¸ **SIFT Descriptors**

* Extracted using OpenCV
* 128-dimensional vectors
* Stored per image
* Used for clustering and histogram generation

### âœ”ï¸ **Swin-B Transformer Descriptors**

* Extracted using pretrained PyTorch Swin-B (backbone only)
* Global average pooled embedding
* Features normalized before clustering

---

## ğŸ› ï¸ BoVW Pipeline

### **1. Feature Quantization (K-Means)**

* Tested cluster sizes: **50, 100, 500**
* Trained only on training descriptors
* Cluster centers saved in `checkpoints/`

### **2. Histogram Construction**

For each image:

1. Assign descriptors to nearest cluster centers
2. Build histogram
3. L1-normalize histogram

---

## ğŸ¤– Classification

### **Linear SVM**

* One-vs-rest strategy
* GridSearchCV hyperparameter tuning

### **Chi-Squared Kernel SVM**

* Precomputed kernel
* Performs well for histogram features

---

## ğŸ“ˆ Evaluation Metrics

* Mean F1-score
* Per-class F1-scores
* Accuracy (balanced & standard)
* Confusion matrices
* Misclassification visualization

  * Shows best/worst-performing classes
  * Example misclassified images (20Ã—20 thumbnails)

---

## ğŸ§ª Example: Predict on Single Image

```bash
python predict.py --image path/to/image.jpg
```

`predict.py` uses:

* Saved model
* Stored scaler
* Vocabulary (cluster centers)
* Class names file

---

## ğŸ“ Report

A full LaTeX report template is included (not in repo) covering:

* Dataset description
* SIFT vs Swin-B comparison
* Preprocessing
* Classifier analysis
* Misclassifications
* Model improvements

---

## ğŸš€ Future Improvements

* Fisher Vector encoding
* VLAD aggregation
* End-to-end Swin-B fine-tuning
* Spatial pyramid matching (SPM)

---

## ğŸ§‘â€ğŸ’» Author

**Amin Abu-Hilga**
BoÄŸaziÃ§i University â€“ CMPE 537 (Fall 2025)
